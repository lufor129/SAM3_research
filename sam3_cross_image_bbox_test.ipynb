{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ece80a",
   "metadata": {},
   "source": [
    "# SAM3 跨圖像邊界框檢測測試\n",
    "\n",
    "本筆記本測試 `sam3_cross_image_bbox.py` 的核心邏輯。它使用參考圖像中的邊界框提示來在目標圖像中檢測相同的物件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384de8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 確保 sam3 在路徑中\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from sam3 import sam3_model_registry, Sam3Processor\n",
    "\n",
    "# 配置\n",
    "CHECKPOINT_PATH = os.path.abspath(\"sam3.pt\")\n",
    "MODEL_TYPE = \"vit_l\"\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"使用設備: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建虛擬數據\n",
    "# 參考圖像：帶有紅色矩形的黑色背景\n",
    "# 目標圖像：帶有紅色矩形和藍色矩形的黑色背景\n",
    "ref_path = \"ref_demo.jpg\"\n",
    "target_path = \"target_demo.jpg\"\n",
    "\n",
    "if not os.path.exists(ref_path):\n",
    "    print(\"正在創建虛擬圖像...\")\n",
    "    \n",
    "    # 參考\n",
    "    ref_img = Image.new('RGB', (400, 400), color='black')\n",
    "    draw = ImageDraw.Draw(ref_img)\n",
    "    draw.rectangle([100, 100, 200, 200], fill='red') # 我們想要檢測的物件\n",
    "    ref_img.save(ref_path)\n",
    "    \n",
    "    # 目標\n",
    "    target_img = Image.new('RGB', (600, 600), color='black')\n",
    "    draw = ImageDraw.Draw(target_img)\n",
    "    draw.rectangle([50, 50, 150, 150], fill='red') # 應該被檢測到\n",
    "    draw.rectangle([400, 100, 500, 200], fill='blue') # 不應該被檢測到\n",
    "    target_img.save(target_path)\n",
    "\n",
    "# 顯示圖像\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(Image.open(ref_path))\n",
    "plt.title(\"參考圖 (尋找紅色)\")\n",
    "# 繪製參考框\n",
    "ax = plt.gca()\n",
    "ref_box = [100, 100, 200, 200]\n",
    "rect = patches.Rectangle((ref_box[0], ref_box[1]), ref_box[2]-ref_box[0], ref_box[3]-ref_box[1], linewidth=2, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(Image.open(target_path))\n",
    "plt.title(\"目標圖 (包含紅色和藍色)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"錯誤: 找不到檢查點 {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(\"正在初始化 SAM3...\")\n",
    "    sam3 = sam3_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "    sam3.to(device=DEVICE)\n",
    "    sam3.eval()\n",
    "    processor = Sam3Processor(sam3, device=DEVICE)\n",
    "    print(\"模型已準備就緒。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行推理\n",
    "# 我們提供參考框給模型，它應該在目標圖像中找到相應的區域。\n",
    "\n",
    "ref_image_pil = Image.open(ref_path).convert(\"RGB\")\n",
    "target_image_pil = Image.open(target_path).convert(\"RGB\")\n",
    "images = [ref_image_pil, target_image_pil]\n",
    "ref_box_list = [[100, 100, 200, 200]] # [x0, y0, x1, y1]\n",
    "\n",
    "print(\"正在處理圖像...\")\n",
    "# 獲取批次特徵\n",
    "batched_input = []\n",
    "for img in images:\n",
    "    batched_input.append({\n",
    "        'image': img,\n",
    "        'original_size': img.size[::-1] # H, W\n",
    "    })\n",
    "    \n",
    "# 因為我們直接使用 Sam3Processor 的內部邏輯（或使用 sam3_cross_image_bbox.py 中的邏輯）\n",
    "# 這裡我們模擬 `sam3_cross_image_bbox.py` 的流程\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # 1. 編碼圖像\n",
    "    output_state = processor.set_image_batch(images)\n",
    "    \n",
    "    # 2. 準備提示\n",
    "    # 參考圖像 (索引 0) 上的盒子\n",
    "    # 注意：processor.set_image_batch 會調整圖像大小，我們需要適當縮放盒子或確保使用正確的 API。\n",
    "    # 為了簡單起見，我們假設 processor 處理了它，或者我們使用 CLI 腳本中的邏輯。\n",
    "    \n",
    "    # 實際上，更簡單的方法是使用我們在 CLI 中實現的 `run_inference` 函數（如果我們可以導入它）。\n",
    "    # 但為了獨立性，我們這裡直接調用模型。\n",
    "    \n",
    "    # 獲取圖像嵌入\n",
    "    # image_embeddings = output_state[\"image_embeddings\"] # 這是高層特徵\n",
    "    \n",
    "    pass\n",
    "\n",
    "print(\"推理步驟通常需要從 sam3_cross_image_bbox.py 導入複雜的邏輯。\")\n",
    "print(\"為簡單起見，我們將展示如何調用命令行工具（如果可用）或僅驗證模型載入。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用命令行工具運行\n",
    "# 這是測試完整流程的最簡單方法。\n",
    "\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"sam3_cross_image_bbox.py\",\n",
    "    \"--ref_image\", ref_path,\n",
    "    \"--target_images\", target_path,\n",
    "    \"--box\", \"100\", \"100\", \"200\", \"200\",\n",
    "    \"--checkpoint\", CHECKPOINT_PATH,\n",
    "    \"--model_type\", MODEL_TYPE,\n",
    "    \"--device\", DEVICE\n",
    "]\n",
    "\n",
    "print(f\"執行命令: {' '.join(cmd)}\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print(\"Stdout:\", result.stdout)\n",
    "print(\"Stderr:\", result.stderr)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"成功！檢查生成的輸出圖像。\")\n",
    "    # 顯示結果（如果有保存的話）\n",
    "    # CLI 默認可能顯示但不保存，或者保存到默認位置。\n",
    "    # 您可能需要修改 CLI 以保存到特定文件以便在此處顯示。\n",
    "else:\n",
    "    print(\"失敗。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "num_py": 3,
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
